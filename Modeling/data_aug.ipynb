{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP+NElN23THwazidaTpKGVc"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o2nps5K5Aqik","executionInfo":{"status":"ok","timestamp":1670306321560,"user_tz":420,"elapsed":18600,"user":{"displayName":"Mahshid Jafarpour","userId":"04753723199669493262"}},"outputId":"f7181d87-6c59-4dda-c135-cd304a82b33a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/MyDrive/task4_materialType\n"]}],"source":["from google.colab import drive\n","\n","drive.mount(\"/content/drive\")\n","%cd '/content/drive/MyDrive/task4_materialType/'"]},{"cell_type":"code","source":["import numpy as np\n","from PIL import Image"],"metadata":{"id":"U7DXU2bVA2VS","executionInfo":{"status":"ok","timestamp":1670306484320,"user_tz":420,"elapsed":202,"user":{"displayName":"Mahshid Jafarpour","userId":"04753723199669493262"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["task = 4\n","if task == 4:\n","        #label: 1: steel, 0: other\n","        org_X_train_data_dir = 'data/task4_X_train.npy'\n","        org_Y_train_data_dir = 'data/task4_y_train.npy'\n","        org_X_test_data_dir = 'data/task4_X_test.npy'\n","        org_Y_test_data_dir = 'data/task4_y_test.npy'\n","        num_classes = 2\n","        claases = ['other', 'steel']\n","elif task == 8:\n","        # label: 0: combined damage, 1: Flexural damage, 2: Undamaged state, 3: Shear damage \n","        org_X_train_data_dir = 'data/task8_X_train.npy'\n","        org_Y_train_data_dir = 'data/task8_y_train.npy'\n","        org_X_test_data_dir = 'data/task8_X_test.npy'\n","        org_Y_test_data_dir = 'data/task8_y_test.npy'\n","        num_classes = 4\n","        claases = ['comb', 'flex', 'ud', 'shear']\n","\n","# x_train_dataset = torch.from_numpy(np.load(org_X_train_data_dir)) \n","# y_train_dataset = torch.from_numpy(np.load(org_Y_train_data_dir)) \n","# x_test_dataset = torch.from_numpy(np.load(org_X_test_data_dir))\n","# y_test_dataset = torch.from_numpy(np.load(org_Y_test_data_dir))\n","\n","# # Make validation set from training\n","# def process_data():\n","    \n","#     # load data\n","#     X_train = np.load(org_X_train_data_dir);\n","#     Y_train = np.load(org_Y_train_data_dir);\n","    \n","#     train_labels = []\n","#     validation_labels = []\n","#     for c in range(num_classes):\n","#         # split data into training and validation, over sampling training data\n","#         index_c = np.where(Y_train == c)[0]\n","#         X_train_c = X_train[index_c[0:nb_class_train[c]],:,:,:]\n","#         X_train_new_c = np.tile(X_train_c,(int(over_sample_train[c]),1,1,1))\n","#         extra_c = int((over_sample_train[c] - int(over_sample_train[c])) * nb_class_train[c])\n","#         X_train_new_c = np.concatenate((X_train_new_c, X_train_c[0:extra_c,:,:,:]))\n","#         Y_train_new_c = np.full((X_train_new_c.shape[0],), c, dtype=int)\n","#         train_labels = np.concatenate((train_labels, Y_train_new_c))\n","        \n","#         # shuffle and store image (training)\n","#         shuffle_train_c = np.random.choice(X_train_new_c.shape[0], X_train_new_c.shape[0], replace=False)\n","#         for i in range(X_train_new_c.shape[0]):\n","#             im = Image.fromarray(X_train_new_c[shuffle_train_c[i], :, :, :])\n","#             im.save(train_data_dir+'/'+str(c)+'/'+str(c)+'_'+str(i)+'.png')\n","        \n","#         # split data into training and validation\n","#         X_val_c = X_train[index_c[nb_class_train[c]:nb_class_train[c]+nb_class_val[c]],:,:,:]\n","#         Y_val_new_c = np.full((X_val_c.shape[0],), c, dtype=int)\n","#         validation_labels = np.concatenate((validation_labels, Y_val_new_c))\n","        \n","#         # shuffle and store image (validation)\n","#         shuffle_val_c = np.random.choice(X_val_c.shape[0], X_val_c.shape[0], replace=False)\n","#         for i in range(X_val_c.shape[0]):\n","#             im = Image.fromarray(X_val_c[shuffle_val_c[i], :, :, :])\n","#             im.save(validation_data_dir+'/'+str(c)+'/'+str(c)+'_'+str(i)+'.png')\n","\n","#     return train_labels, validation_labels\n","# train_labels, validation_labels = process_data()\n"],"metadata":{"id":"CnifGn6_BB_h","executionInfo":{"status":"ok","timestamp":1670306506061,"user_tz":420,"elapsed":203,"user":{"displayName":"Mahshid Jafarpour","userId":"04753723199669493262"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["### fancy-pca\n","ref: https://github.com/wenyiyen/CS230-Final-Project/blob/master/fancy_pca.ipynb\n","In order to further improve on performance, we tried Fancy PCA as one of our data augmentation methods. It is found to be effective on “texture-type” classification, such as damage/no damage and spalling/no spalling. For other tasks, the improvement is not significant. [Yen & Zhang]"],"metadata":{"id":"Qap6zKTMBLwK"}},{"cell_type":"code","source":["# fancy pca \n","# \n","def data_aug(img):\n","    mu = 0\n","    sigma = 0.1\n","    feature_vec=np.matrix(evecs_mat)\n","\n","    # 3 x 1 scaled eigenvalue matrix\n","    se = np.zeros((3,1))\n","    se[0][0] = np.random.normal(mu, sigma)*evals[0]\n","    se[1][0] = np.random.normal(mu, sigma)*evals[1]\n","    se[2][0] = np.random.normal(mu, sigma)*evals[2]\n","    se = np.matrix(se)\n","    val = feature_vec*se\n","\n","    # Parse through every pixel value.\n","    for i in range(img.shape[0]):\n","        for j in range(img.shape[1]):\n","            # Parse through every dimension.\n","            for k in range(img.shape[2]):\n","                img[i,j,k] = float(img[i,j,k]) + float(val[k])"],"metadata":{"id":"3Cu0C78iBK3_","executionInfo":{"status":"ok","timestamp":1670306529451,"user_tz":420,"elapsed":133,"user":{"displayName":"Mahshid Jafarpour","userId":"04753723199669493262"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["x_train_dataset = np.load(org_X_train_data_dir)\n","y_train_dataset = np.load(org_Y_train_data_dir)"],"metadata":{"id":"zvMCW4cyB4A1","executionInfo":{"status":"ok","timestamp":1670306692519,"user_tz":420,"elapsed":368,"user":{"displayName":"Mahshid Jafarpour","userId":"04753723199669493262"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["x_train_dataset.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CXK77oCaCIp8","executionInfo":{"status":"ok","timestamp":1670306640859,"user_tz":420,"elapsed":210,"user":{"displayName":"Mahshid Jafarpour","userId":"04753723199669493262"}},"outputId":"24058e5e-6705-473f-f3cd-28797459e5bb"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(8312, 224, 224, 3)"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["y_train_dataset[y_train_dataset==[0, 1]].shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r0VouxsFCL_T","executionInfo":{"status":"ok","timestamp":1670306739195,"user_tz":420,"elapsed":136,"user":{"displayName":"Mahshid Jafarpour","userId":"04753723199669493262"}},"outputId":"b089c539-5bfb-4dc0-d0b0-1f00b98cc496"},"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(3612,)"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["indices = (y_train_dataset==[0, 1])\n","class2_x = x_train_dataset[indices[:,0], :, :, :]"],"metadata":{"id":"X2wVDGoKCl-g","executionInfo":{"status":"ok","timestamp":1670306906588,"user_tz":420,"elapsed":334,"user":{"displayName":"Mahshid Jafarpour","userId":"04753723199669493262"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"hmieIJ2zDMwv"},"execution_count":null,"outputs":[]}]}